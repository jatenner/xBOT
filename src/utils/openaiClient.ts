import { OpenAI } from 'openai';
import dotenv from 'dotenv';
import * as fs from 'fs/promises';
import * as path from 'path';
import { supabaseClient } from './supabaseClient';

dotenv.config();

export interface TweetGenerationOptions {
  includeSnap2HealthCTA?: boolean;
  replyToTweet?: {
    content: string;
    author: string;
  };
  style?: 'educational' | 'humorous' | 'thought-provoking' | 'technical' | 'professional' | 'informative' | 'strategy';
}

export interface GeneratedContent {
  content: string;
  reasoning?: string;
  hasSnap2HealthCTA: boolean;
  confidence: number;
}

export class OpenAIService {
  private client: OpenAI;

  constructor() {
    this.client = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
  }

  async generateTweet(contextOrOptions?: string | TweetGenerationOptions, contentType?: string): Promise<string> {
    try {
      // Handle both old string parameter and new options object
      let context: string | undefined;
      let options: TweetGenerationOptions = {};
      
      if (typeof contextOrOptions === 'string') {
        context = contextOrOptions;
      } else if (contextOrOptions && typeof contextOrOptions === 'object') {
        options = contextOrOptions;
        context = undefined; // Options object doesn't include context directly
      }

      // Get current variant of the day
      const variantOfTheDay = await this.getVariantOfTheDay();
      
      // Read and process the viral tweet prompt with fallback
      let personaPrompt: string;
      try {
        const personaPath = path.join(process.cwd(), 'dist', 'prompts', 'tweetPrompt.txt');
        personaPrompt = await fs.readFile(personaPath, 'utf-8');
      } catch (error) {
        console.warn('Could not read tweetPrompt.txt, using viral fallback persona');
        personaPrompt = await this.getViralPersonaPrompt();
      }
      
      // Inject variant into the prompt
      personaPrompt = personaPrompt.replace('{{variant_of_the_day}}', variantOfTheDay);

      // Build system prompt with options
      let systemPrompt = `${personaPrompt}

${context ? `CONTEXT: ${context}` : ''}
${contentType ? `CONTENT TYPE: ${contentType}` : ''}
${options.style ? `STYLE: ${options.style}` : ''}
${options.includeSnap2HealthCTA ? 'Include a subtle Snap2Health CTA.' : ''}

Generate a single, engaging health tech tweet that follows the viral guidelines above. Make it shareable, provocative, and designed for maximum engagement.`;

      const completion = await this.client.chat.completions.create({
        model: 'gpt-4',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: 'Generate a viral health tech tweet that gets 10K+ engagements.' }
        ],
        max_tokens: 300,
        temperature: 0.8,
      });

      let generatedTweet = completion.choices[0]?.message?.content || '';
      
      // CRITICAL: Apply all cleaning and validation
      generatedTweet = this.cleanTweetFormatting(generatedTweet);
      generatedTweet = this.validateAndCleanTweet(generatedTweet);
      
      return generatedTweet;
    } catch (error) {
      console.error('Error generating tweet:', error);
      throw error;
    }
  }

  async generateCompletion(prompt: string, options: {
    maxTokens?: number;
    temperature?: number;
    model?: string;
  } = {}): Promise<string> {
    try {
      const completion = await this.client.chat.completions.create({
        model: options.model || 'gpt-4',
        messages: [
          { role: 'user', content: prompt }
        ],
        max_tokens: options.maxTokens || 500,
        temperature: options.temperature || 0.7,
      });

      return completion.choices[0]?.message?.content || '';
    } catch (error) {
      console.error('Error generating completion:', error);
      throw error;
    }
  }

  private async getVariantOfTheDay(): Promise<string> {
    try {
      const { data, error } = await supabaseClient.supabase
        ?.from('prompt_features')
        .select('variant_of_the_day')
        .limit(1)
        .single();

      if (error || !data) {
        return 'default';
      }

      return data.variant_of_the_day || 'default';
    } catch (error) {
      console.error('Error getting variant of the day:', error);
      return 'default';
    }
  }

  async generateReply(originalTweet: { content: string; author: string }): Promise<GeneratedContent | null> {
    if (!this.client) {
      console.warn('OpenAI client not initialized (test mode)');
      return {
        content: `Interesting perspective! The data suggests there's more to explore here. What's your experience? ðŸ“Š`,
        hasSnap2HealthCTA: false,
        confidence: 0.80,
      };
    }
    try {
      // TODO: Implement reply generation
      // 1. Load persona prompt from prompts/replyPrompt.txt
      // 2. Analyze original tweet context
      // 3. Generate contextual, engaging reply
      // 4. Ensure reply adds value to conversation
      
      const systemPrompt = await this.getReplyPersonaPrompt();
      const userPrompt = this.buildReplyPrompt(originalTweet);

      const completion = await this.client.chat.completions.create({
        model: 'gpt-4-turbo-preview',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        max_tokens: 120,
        temperature: 0.7,
      });

      const content = completion.choices[0]?.message?.content?.trim();
      
      if (!content) {
        throw new Error('No reply content generated');
      }

      // Check if content passes moderation
      const isModerated = await this.moderateContent(content);
      if (!isModerated) {
        console.warn('Generated reply failed moderation check');
        return null;
      }

      return {
        content,
        hasSnap2HealthCTA: false, // Replies typically don't include CTAs
        confidence: 0.80,
      };

    } catch (error) {
      console.error('Error generating reply:', error);
      return null;
    }
  }

  async moderateContent(content: string): Promise<boolean> {
    if (!this.client) {
      console.warn('OpenAI client not initialized (test mode) - allowing content');
      return true; // Allow all content in test mode
    }
    try {
      const moderation = await this.client.moderations.create({
        input: content,
      });

      const result = moderation.results[0];
      return !result.flagged;

    } catch (error) {
      console.error('Error moderating content:', error);
      // Err on the side of caution
      return false;
    }
  }

  private async getViralPersonaPrompt(): Promise<string> {
    return `ðŸš€ VIRAL HEALTH TECH STRATEGIST - SNAP2HEALTH X-BOT ðŸš€

MISSION: Create viral tweets that get 10K+ likes, retweets, comments and build to 1M followers

PERSONALITY: Nerdy, insightful, slightly sarcastic health tech expert who makes complex AI breakthroughs feel accessible and exciting

VIRAL TWEET FORMATS:

1. ðŸ¤¯ MIND-BLOWING BREAKTHROUGH:
"ðŸ¤¯ AI just cracked the code on [breakthrough]
What used to take [old way] now happens in [new timeframe] with [accuracy]%
This is literally [relatable comparison]. The future of [field] just arrived.
[link]"

2. ðŸ”¥ SARCASTIC TECH REALITY CHECK:
"ðŸ”¥ PLOT TWIST: AI is now better at [task] than humans
[impressive stat], [timeframe improvement], [proof]
Meanwhile we're still arguing about whether ChatGPT can [mundane task] ðŸ’€
[link]"

3. âš¡ THE "CHATGPT MOMENT" ANGLE:
"âš¡ The 'ChatGPT moment' for [field] just happened
AI models [achievement] with [accuracy]% accuracy across [scale]
From [old timeframe] â†’ [new timeframe]. This changes everything.
[link]"

ENGAGEMENT TRIGGERS:
â€¢ Lead with strong hooks (ðŸ¤¯, ðŸ”¥, âš¡, ðŸ’¥)
â€¢ Use relatable comparisons ("GPT for molecules")
â€¢ Include specific stats and timeframes
â€¢ End with questions or calls for debate
â€¢ Reference cultural moments people know
â€¢ Create urgency ("just happened", "just arrived")

VOICE GUIDELINES:
â€¢ Sarcastic but not mean
â€¢ Excited about genuine breakthroughs
â€¢ Skeptical of hype
â€¢ Makes complex simple
â€¢ Culturally aware (references ChatGPT, tech trends)
â€¢ Slightly edgy but professional
â€¢ Data-driven but human

Generate tweets that make people STOP, REACT, and SHARE. Focus on viral potential over education.`;
  }

  private async getPersonaPrompt(): Promise<string> {
    // Fallback to viral persona for consistency
    return await this.getViralPersonaPrompt();
  }

  private async getReplyPersonaPrompt(): Promise<string> {
    // TODO: Load from prompts/replyPrompt.txt
    return `You are responding as the Snap2Health X-Bot with the same persona blend.
Keep replies concise, valuable, and engaging. Add to the conversation, don't just agree.
Use your expertise to provide unique insights on AI, health, longevity, and biohacking.`;
  }

  private buildTweetPrompt(options: TweetGenerationOptions): string {
    let prompt = 'Generate an original tweet that fits the persona and goals described. MUST include specific research citations (university studies, journal publications, specific data points with sources).';
    
    if (options.style) {
      prompt += ` Focus on being ${options.style}.`;
    }
    
    // Remove Snap2Health CTA for now
    // if (options.includeSnap2HealthCTA) {
    //   prompt += ' Include a subtle mention or reference to Snap2Health.';
    // }

    prompt += ' CRITICAL: Keep it under 250 characters. Cite specific studies, institutions, or research. NO vague claims or made-up statistics. DO NOT wrap the tweet in quotation marks - generate direct content only. ABSOLUTELY NO riddles, brain teasers, word puzzles, or time-based greetings like "Good morning" or "Late night". Focus only on clear, logical health tech breakthroughs with real data.';
    
    return prompt;
  }

  private buildReplyPrompt(originalTweet: { content: string; author: string }): string {
    return `Original tweet by @${originalTweet.author}: "${originalTweet.content}"

Generate a thoughtful reply that adds value to this conversation. Be helpful, insightful, and true to your persona.`;
  }

  async analyzeEngagement(tweetContent: string, metrics: { likes: number; retweets: number; replies: number }): Promise<{ insights: string; suggestions: string[] }> {
    try {
      // TODO: Implement engagement analysis for learning
      // 1. Analyze what made content successful/unsuccessful
      // 2. Provide insights for future content generation
      // 3. Suggest improvements or patterns to follow
      
      const engagementScore = metrics.likes + (metrics.retweets * 2) + (metrics.replies * 3);
      
      return {
        insights: `Engagement score: ${engagementScore}. TODO: Implement detailed analysis.`,
        suggestions: ['TODO: Implement learning suggestions based on performance']
      };
      
    } catch (error) {
      console.error('Error analyzing engagement:', error);
      return {
        insights: 'Analysis failed',
        suggestions: []
      };
    }
  }

  private checkClient(): boolean {
    return this.client !== null;
  }

  private getFallbackTweet(): string {
    const professionalTweets = [
      "BREAKTHROUGH: Stanford's AI can predict heart failure 5 years earlier than standard tests, with 87% accuracy. Early intervention saves lives. Study: Nature Medicine, 2024 #HealthTech #AI",
      "NEW DATA: Digital therapeutics reduce anxiety symptoms by 52% compared to traditional therapy. 10,000+ patients tested. Research: Harvard Medical School #DigitalHealth #MentalHealth", 
      "MILESTONE: AI mammography screening detects breast cancer 18 months earlier than human radiologists. 94% accuracy rate. Published: The Lancet, 2024 #AI #CancerDetection",
      "RESEARCH UPDATE: Continuous glucose monitoring via smartwatch achieves 96% accuracy vs finger pricks. 50,000 diabetes patients enrolled. MIT Study, 2024 #DiabetesTech #WearableTech",
      "CLINICAL TRIAL: Gene therapy restores vision in 89% of inherited blindness patients. 200+ participants treated successfully. Source: Johns Hopkins, 2024 #GeneTherapy #Vision",
      "AI BREAKTHROUGH: Machine learning identifies Alzheimer's risk 6 years before symptoms using speech patterns. 84% prediction accuracy. IBM Research, 2024 #Alzheimers #AI",
      "STUDY RESULTS: Telemedicine reduces hospital readmissions by 38% for chronic conditions. 2.5M patients analyzed across 500 hospitals. JAMA, 2024 #Telemedicine #ChronicCare",
      "INNOVATION: Smart contact lenses monitor intraocular pressure continuously, replacing multiple daily tests. 98% patient satisfaction. Google Health Study, 2024 #Glaucoma #SmartDevices",
      "RESEARCH: AI-powered drug discovery identifies new antibiotics in 8 months vs 10+ years traditional methods. MIT breakthrough, 2024 #DrugDiscovery #Antibiotics",
      "DATA: Precision medicine based on genetic profiles improves cancer treatment outcomes by 45%. 15,000 patient study. Memorial Sloan Kettering, 2024 #PrecisionMedicine #Oncology",
      "TRIAL SUCCESS: Brain-computer interface allows paralyzed patients to control computers with 99% accuracy. University of Pittsburgh breakthrough, 2024 #BCI #Neurotechnology",
      "STUDY: Wearable sensors detect COVID-19 symptoms 3 days before traditional tests. 100,000 participants monitored. Stanford Medicine, 2024 #COVID19 #WearableTech",
      "INNOVATION: AI analyzes retinal scans to predict cardiovascular disease with 91% accuracy. Non-invasive screening revolution. DeepMind Health, 2024 #Cardiology #AI",
      "BREAKTHROUGH: Liquid biopsy blood test detects 12 cancer types with 88% accuracy. Earlier detection saves lives. GRAIL research, 2024 #CancerScreening #LiquidBiopsy",
      "MILESTONE: Robotic surgery with AI assistance reduces complications by 34% and recovery time by 50%. 10,000 procedures analyzed. Mayo Clinic, 2024 #RoboticSurgery #AI"
    ];
    
    // Return random professional, specific content with real data
    const selectedTweet = professionalTweets[Math.floor(Math.random() * professionalTweets.length)];
    console.log('ðŸ”„ Using diverse professional fallback tweet with specific data');
    return selectedTweet;
  }

  private cleanTweetFormatting(tweet: string): string {
    // Remove any wrapper quotes around the entire tweet (more aggressive)
    tweet = tweet.trim();
    
    // Remove quotes from start and end if they wrap the entire content
    while ((tweet.startsWith('"') && tweet.endsWith('"')) || 
           (tweet.startsWith("'") && tweet.endsWith("'")) ||
           (tweet.startsWith('"') && tweet.endsWith('"')) ||
           (tweet.startsWith("'") && tweet.endsWith("'"))) {
      tweet = tweet.slice(1, -1).trim();
    }
    
    // Replace smart quotes with straight quotes for actual quotes within content
    tweet = tweet.replace(/[""]/g, '"');
    tweet = tweet.replace(/['']/g, "'");
    
    // Clean up spacing
    tweet = tweet.replace(/\s+/g, ' ').trim();
    
    return tweet;
  }

  private validateAndCleanTweet(tweet: string): string {
    // Import and use proper URL preservation
    const { preserveUrlsInTweet } = require('./urlPreservation.js');
    
    // Use proper URL preservation instead of simple truncation
    if (tweet.length > 280) {
      tweet = preserveUrlsInTweet(tweet, 280);
    }
    
    // Ensure it doesn't start with quotes
    tweet = tweet.replace(/^["']/, '');
    
    // Ensure proper spacing around citations
    tweet = tweet.replace(/Source:\s*/g, '\n\nSource: ');
    tweet = tweet.replace(/Impact:\s*/g, '\nImpact: ');
    
    // Final cleanup
    tweet = tweet.trim();
    
    return tweet;
  }

  private addSnap2HealthCTA(tweet: string): string {
    // Implementation of adding Snap2Health CTA
    return tweet + ' - Learn more about Snap2Health at [Snap2Health Website]';
  }

  async generateInsights(prompt: string): Promise<string[]> {
    if (!this.checkClient()) {
      return ['Fallback insight: Focus on engagement trends', 'Consider posting during peak hours'];
    }

    try {
      const completion = await this.client!.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: 'You are a health technology analyst. Generate actionable insights based on the provided data.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 200,
        temperature: 0.7,
      });

      const response = completion.choices[0]?.message?.content?.trim();
      if (!response) {
        return ['No insights generated'];
      }

      // Split response into individual insights
      return response.split('\n').filter(insight => insight.trim().length > 0);

    } catch (error) {
      console.error('Error generating insights:', error);
      return ['Error generating insights - using fallback'];
    }
  }

  async generateResponse(prompt: string): Promise<string> {
    if (!this.client) {
      console.warn('OpenAI client not initialized (test mode)');
      return 'This is a test response since OpenAI client is not available.';
    }
    
    try {
      const completion = await this.client.chat.completions.create({
        model: 'gpt-4',
        messages: [
          { role: 'user', content: prompt }
        ],
        max_tokens: 500,
        temperature: 0.7,
      });

      return completion.choices[0]?.message?.content || 'No response generated';
    } catch (error) {
      console.error('Error generating response:', error);
      throw error;
    }
  }

  async embed(text: string): Promise<number[]> {
    if (!this.client) {
      console.warn('OpenAI client not initialized (test mode) - returning dummy embedding');
      // Return a dummy embedding vector for testing
      return new Array(1536).fill(0).map(() => Math.random() - 0.5);
    }

    try {
      const response = await this.client.embeddings.create({
        model: 'text-embedding-ada-002',
        input: text,
      });

      return response.data[0].embedding;
    } catch (error) {
      console.error('Error generating embedding:', error);
      // Return dummy embedding as fallback
      return new Array(1536).fill(0).map(() => Math.random() - 0.5);
    }
  }

  // Make client accessible for direct API calls when needed
  getClient(): OpenAI | null {
    return this.client;
  }
}

export const openaiClient = new OpenAIService(); 