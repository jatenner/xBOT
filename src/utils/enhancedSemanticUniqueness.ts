/**
 * üß† ENHANCED SEMANTIC UNIQUENESS SYSTEM
 * 
 * Advanced content deduplication using OpenAI embeddings with:
 * - 30-day historical comparison
 * - 0.88 cosine similarity threshold
 * - 30 regeneration attempts
 * - Supabase embedding storage
 * - Comprehensive logging
 */

import { OpenAI } from 'openai';
import { supabaseClient } from './supabaseClient';
import { emergencyBudgetLockdown } from './emergencyBudgetLockdown';

interface SemanticAnalysis {
  isUnique: boolean;
  maxSimilarity: number;
  similarTweet?: {
    id: string;
    content: string;
    similarity: number;
    created_at: string;
  };
  attemptNumber: number;
  embedding: number[];
}

interface UniquenessResult {
  success: boolean;
  isUnique: boolean;
  analysis: SemanticAnalysis;
  error?: string;
}

export class EnhancedSemanticUniqueness {
  private static readonly SIMILARITY_THRESHOLD = 0.88;
  private static readonly MAX_ATTEMPTS = 30;
  private static readonly DAYS_TO_CHECK = 30;
  private static openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

  /**
   * üéØ MAIN UNIQUENESS CHECK
   */
  static async checkUniqueness(
    candidateText: string,
    attemptNumber: number = 1
  ): Promise<UniquenessResult> {
    try {
      console.log(`üîç Uniqueness check attempt ${attemptNumber}/${this.MAX_ATTEMPTS}: "${candidateText.substring(0, 60)}..."`);

      // Generate embedding for candidate
      const embedding = await this.generateEmbedding(candidateText);
      if (!embedding) {
        return {
          success: false,
          isUnique: true, // Assume unique if embedding fails
          analysis: {
            isUnique: true,
            maxSimilarity: 0,
            attemptNumber,
            embedding: []
          },
          error: 'Failed to generate embedding'
        };
      }

      // Get historical tweets for comparison
      const historicalTweets = await this.getHistoricalTweets();
      
      let maxSimilarity = 0;
      let mostSimilarTweet: any = null;

      // Compare against each historical tweet
      for (const tweet of historicalTweets) {
        if (tweet.semantic_embedding && Array.isArray(tweet.semantic_embedding)) {
          const similarity = this.calculateCosineSimilarity(embedding, tweet.semantic_embedding);
          
          if (similarity > maxSimilarity) {
            maxSimilarity = similarity;
            mostSimilarTweet = {
              id: tweet.id,
              content: tweet.content,
              similarity,
              created_at: tweet.created_at
            };
          }
        }
      }

      const isUnique = maxSimilarity < this.SIMILARITY_THRESHOLD;

      const analysis: SemanticAnalysis = {
        isUnique,
        maxSimilarity,
        similarTweet: mostSimilarTweet,
        attemptNumber,
        embedding
      };

      // Log the analysis
      await this.logUniquenessAttempt(candidateText, analysis);

      // Store embedding if content is unique
      if (isUnique) {
        console.log(`‚úÖ Content is unique (max similarity: ${maxSimilarity.toFixed(3)})`);
      } else {
        console.log(`üö´ Content too similar (${maxSimilarity.toFixed(3)} > ${this.SIMILARITY_THRESHOLD})`);
        if (mostSimilarTweet) {
          console.log(`üìù Similar to: "${mostSimilarTweet.content.substring(0, 60)}..." (${mostSimilarTweet.created_at})`);
        }
      }

      return {
        success: true,
        isUnique,
        analysis
      };

    } catch (error) {
      console.error('‚ùå Uniqueness check failed:', error);
      return {
        success: false,
        isUnique: true, // Assume unique on error to avoid blocking
        analysis: {
          isUnique: true,
          maxSimilarity: 0,
          attemptNumber,
          embedding: []
        },
        error: error instanceof Error ? error.message : 'Unknown error'
      };
    }
  }

  /**
   * üßÆ GENERATE OPENAI EMBEDDING
   */
  private static async generateEmbedding(text: string): Promise<number[] | null> {
    try {
      // Budget check
      await emergencyBudgetLockdown.enforceBeforeAICall('embedding-generation');

      const response = await this.openai.embeddings.create({
        model: 'text-embedding-3-small',
        input: text.replace(/\n/g, ' ').trim(),
      });

      return response.data[0]?.embedding || null;
    } catch (error) {
      console.error('‚ùå Failed to generate embedding:', error);
      return null;
    }
  }

  /**
   * üìä GET HISTORICAL TWEETS (30 DAYS)
   */
  private static async getHistoricalTweets(): Promise<any[]> {
    try {
      const thirtyDaysAgo = new Date();
      thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - this.DAYS_TO_CHECK);

      const { data, error } = await supabaseClient.supabase
        .from('tweets')
        .select('id, content, semantic_embedding, created_at')
        .gte('created_at', thirtyDaysAgo.toISOString())
        .not('semantic_embedding', 'is', null)
        .order('created_at', { ascending: false })
        .limit(500); // Reasonable limit for performance

      if (error) {
        console.error('‚ùå Failed to fetch historical tweets:', error);
        return [];
      }

      return data || [];
    } catch (error) {
      console.error('‚ùå Database query failed:', error);
      return [];
    }
  }

  /**
   * üßÆ CALCULATE COSINE SIMILARITY
   */
  private static calculateCosineSimilarity(a: number[], b: number[]): number {
    if (a.length !== b.length) return 0;

    let dotProduct = 0;
    let normA = 0;
    let normB = 0;

    for (let i = 0; i < a.length; i++) {
      dotProduct += a[i] * b[i];
      normA += a[i] * a[i];
      normB += b[i] * b[i];
    }

    const magnitude = Math.sqrt(normA) * Math.sqrt(normB);
    return magnitude === 0 ? 0 : dotProduct / magnitude;
  }

  /**
   * üìù LOG UNIQUENESS ATTEMPT
   */
  private static async logUniquenessAttempt(
    candidateText: string,
    analysis: SemanticAnalysis
  ): Promise<void> {
    try {
      await supabaseClient.supabase
        .from('uniqueness_logs')
        .insert({
          candidate_text: candidateText,
          is_unique: analysis.isUnique,
          max_similarity: analysis.maxSimilarity,
          attempt_number: analysis.attemptNumber,
          similar_tweet_id: analysis.similarTweet?.id,
          threshold_used: this.SIMILARITY_THRESHOLD,
          created_at: new Date().toISOString()
        });
    } catch (error) {
      console.error('‚ùå Failed to log uniqueness attempt:', error);
    }
  }

  /**
   * üíæ STORE EMBEDDING FOR FUTURE COMPARISON
   */
  static async storeEmbedding(tweetId: string, embedding: number[]): Promise<void> {
    try {
      await supabaseClient.supabase
        .from('tweets')
        .update({ semantic_embedding: embedding })
        .eq('id', tweetId);

      console.log(`üíæ Stored embedding for tweet ${tweetId}`);
    } catch (error) {
      console.error('‚ùå Failed to store embedding:', error);
    }
  }

  /**
   * üìä GET UNIQUENESS STATISTICS
   */
  static async getUniquenessStats(): Promise<{
    totalAttempts: number;
    uniqueContent: number;
    duplicateContent: number;
    averageSimilarity: number;
    successRate: number;
  }> {
    try {
      const { data, error } = await supabaseClient.supabase
        .from('uniqueness_logs')
        .select('is_unique, max_similarity')
        .gte('created_at', new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString());

      if (error || !data) {
        return {
          totalAttempts: 0,
          uniqueContent: 0,
          duplicateContent: 0,
          averageSimilarity: 0,
          successRate: 0
        };
      }

      const totalAttempts = data.length;
      const uniqueContent = data.filter(log => log.is_unique).length;
      const duplicateContent = totalAttempts - uniqueContent;
      const averageSimilarity = data.reduce((sum, log) => sum + log.max_similarity, 0) / totalAttempts;
      const successRate = totalAttempts > 0 ? (uniqueContent / totalAttempts) * 100 : 0;

      return {
        totalAttempts,
        uniqueContent,
        duplicateContent,
        averageSimilarity,
        successRate
      };
    } catch (error) {
      console.error('‚ùå Failed to get uniqueness stats:', error);
      return {
        totalAttempts: 0,
        uniqueContent: 0,
        duplicateContent: 0,
        averageSimilarity: 0,
        successRate: 0
      };
    }
  }
}

export const enhancedSemanticUniqueness = EnhancedSemanticUniqueness; 