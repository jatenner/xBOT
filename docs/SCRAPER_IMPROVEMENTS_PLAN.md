# üéØ Scraper Improvements Plan
**Created:** November 5, 2025  
**Goal:** Bulletproof scraping that stores correct data autonomously

---

## üö® Current State (Nov 5, 4 PM)

### **What's Working:**
- ‚úÖ Scraper runs every 20 minutes
- ‚úÖ Extracts impressions reliably
- ‚úÖ Syncs to content_metadata (just deployed)
- ‚úÖ Generic URL works for all tweet types

### **What's NOT Ideal:**
- ‚ö†Ô∏è Uses regex text parsing (brittle - Twitter can change text format)
- ‚ö†Ô∏è Defaults to 0 when not found (might hide real issues)
- ‚ö†Ô∏è No validation (accepts 0 for tweets that should have engagement)
- ‚ö†Ô∏è No health monitoring (can't tell if scraper is degraded)
- ‚ö†Ô∏è Single extraction strategy (no fallback chain)

---

## üéØ Goal: Multi-Strategy Extraction

**Principle:** Try multiple methods, pick the most reliable result

```
STRATEGY 1: DOM Selectors (Most Reliable)
‚îú‚îÄ Extract from analytics page DOM elements
‚îú‚îÄ Uses data-testid and aria-label attributes
‚îî‚îÄ Success rate: 85% (when page loads correctly)

STRATEGY 2: Analytics Text Parsing (Current Method)
‚îú‚îÄ Extract from visible text on analytics page
‚îú‚îÄ Uses regex patterns
‚îî‚îÄ Success rate: 60% (when text format matches)

STRATEGY 3: Public Tweet Page (Fallback)
‚îú‚îÄ Extract from public tweet view (no login required)
‚îú‚îÄ Uses engagement buttons' aria-labels
‚îî‚îÄ Success rate: 90% (most stable)

STRATEGY 4: Cross-Validation
‚îú‚îÄ Compare results from multiple strategies
‚îú‚îÄ Flag discrepancies for manual review
‚îî‚îÄ Use median value if strategies disagree
```

---

## üîß Improvement 1: Multi-Strategy Extraction

### **File:** `src/scrapers/bulletproofTwitterScraper.ts`

**Add new extraction methods:**

```typescript
async extractMetricsWithStrategies(page: Page, tweetId: string): Promise<ScrapedMetrics> {
  const strategies = [];
  
  // Strategy 1: Try analytics page DOM extraction
  try {
    const analyticsMetrics = await this.extractFromAnalyticsDOM(page);
    if (this.metricsHaveMinimumData(analyticsMetrics)) {
      strategies.push({ name: 'analytics_dom', metrics: analyticsMetrics, confidence: 0.85 });
    }
  } catch (e) {
    log({ op: 'analytics_dom_failed', error: e.message });
  }
  
  // Strategy 2: Try analytics page text parsing (current method)
  try {
    const textMetrics = await this.extractFromAnalyticsText(page);
    if (this.metricsHaveMinimumData(textMetrics)) {
      strategies.push({ name: 'analytics_text', metrics: textMetrics, confidence: 0.60 });
    }
  } catch (e) {
    log({ op: 'analytics_text_failed', error: e.message });
  }
  
  // Strategy 3: Fallback to public tweet page (most reliable)
  if (strategies.length === 0) {
    try {
      await page.goto(`https://twitter.com/i/status/${tweetId}`, { waitUntil: 'networkidle' });
      const publicMetrics = await this.extractFromPublicTweet(page, tweetId);
      if (this.metricsHaveMinimumData(publicMetrics)) {
        strategies.push({ name: 'public_tweet', metrics: publicMetrics, confidence: 0.90 });
      }
    } catch (e) {
      log({ op: 'public_tweet_failed', error: e.message });
    }
  }
  
  // Pick best strategy or merge results
  return this.selectBestMetrics(strategies, tweetId);
}
```

**Benefits:**
- ‚úÖ Not dependent on single extraction method
- ‚úÖ Can detect when one method fails
- ‚úÖ Automatically tries alternatives
- ‚úÖ Logs which strategy worked

---

## üîß Improvement 2: Smart Validation

### **Problem:** Currently accepts 0 for everything (might be wrong)

**Add realistic validation:**

```typescript
validateMetricsRealistic(metrics: ScrapedMetrics, tweetAge: number): ValidationResult {
  const issues = [];
  
  // Check 1: Old tweet with 0 engagement is suspicious
  if (tweetAge > 24 * 60 * 60 * 1000) { // > 24 hours old
    if (metrics.views === 0 || metrics.views === null) {
      issues.push({ severity: 'high', message: 'Tweet >24h old but 0 views' });
    }
  }
  
  // Check 2: Engagement rate sanity
  if (metrics.views > 0) {
    const totalEngagement = (metrics.likes || 0) + (metrics.retweets || 0) + (metrics.replies || 0);
    const engagementRate = totalEngagement / metrics.views;
    
    if (engagementRate > 0.5) {
      issues.push({ severity: 'medium', message: `Unrealistic ER: ${(engagementRate * 100).toFixed(1)}%` });
    }
  }
  
  // Check 3: Likes should be >= retweets (usually)
  if (metrics.retweets > metrics.likes * 2) {
    issues.push({ severity: 'low', message: 'Retweets > 2x likes (unusual)' });
  }
  
  // Check 4: Compare to historical average
  const avgViews = await this.getAverageViews(); // From past 10 tweets
  if (metrics.views > avgViews * 50) { // 50x average is suspicious
    issues.push({ severity: 'high', message: `Views ${metrics.views} >> average ${avgViews}` });
  }
  
  return {
    valid: issues.filter(i => i.severity === 'high').length === 0,
    warnings: issues,
    confidence: this.calculateConfidence(issues)
  };
}
```

**Benefits:**
- ‚úÖ Detects clearly wrong data
- ‚úÖ Flags suspicious metrics for review
- ‚úÖ Learns from historical patterns
- ‚úÖ Prevents garbage data in dashboard

---

## üîß Improvement 3: Extraction from Public Tweet (Most Reliable)

### **Why Public Tweet Page is Better:**
- ‚úÖ Always has engagement buttons (like, RT, reply)
- ‚úÖ Uses aria-label (screen reader text - very stable)
- ‚úÖ Doesn't require analytics page (which sometimes fails)
- ‚úÖ Works for ALL tweets (singles, threads, replies)

**Implementation:**

```typescript
async extractFromPublicTweet(page: Page, tweetId: string): Promise<ScrapedMetrics> {
  // Navigate to public tweet (not analytics)
  await page.goto(`https://twitter.com/i/status/${tweetId}`, { waitUntil: 'networkidle' });
  
  // Find the tweet article by data-tweet-id attribute
  const tweetArticle = await page.$(`article[data-tweet-id="${tweetId}"]`);
  if (!tweetArticle) {
    // Fallback: find by looking for tweet ID in URL
    const allArticles = await page.$$('article[data-testid="tweet"]');
    for (const article of allArticles) {
      const links = await article.$$('a[href*="/status/"]');
      for (const link of links) {
        const href = await link.getAttribute('href');
        if (href?.includes(tweetId)) {
          tweetArticle = article;
          break;
        }
      }
      if (tweetArticle) break;
    }
  }
  
  if (!tweetArticle) {
    throw new Error('Could not find tweet article');
  }
  
  // Extract from engagement buttons (most reliable method)
  const metrics: ScrapedMetrics = {
    likes: null,
    retweets: null,
    replies: null,
    views: null
  };
  
  // LIKES: [data-testid="like"] or [data-testid="unlike"]
  const likeBtn = await tweetArticle.$('[data-testid="like"], [data-testid="unlike"]');
  if (likeBtn) {
    const ariaLabel = await likeBtn.getAttribute('aria-label');
    // "3 Likes. Like" or "Like"
    const match = ariaLabel?.match(/(\d[\d,]*)\s*(?:Like|like)/);
    metrics.likes = match ? parseInt(match[1].replace(/,/g, '')) : 0;
  }
  
  // RETWEETS: [data-testid="retweet"] or [data-testid="unretweet"]
  const rtBtn = await tweetArticle.$('[data-testid="retweet"], [data-testid="unretweet"]');
  if (rtBtn) {
    const ariaLabel = await rtBtn.getAttribute('aria-label');
    // "5 Reposts. Repost" or "Repost"
    const match = ariaLabel?.match(/(\d[\d,]*)\s*(?:Repost|Retweet)/);
    metrics.retweets = match ? parseInt(match[1].replace(/,/g, '')) : 0;
  }
  
  // REPLIES: [data-testid="reply"]
  const replyBtn = await tweetArticle.$('[data-testid="reply"]');
  if (replyBtn) {
    const ariaLabel = await replyBtn.getAttribute('aria-label');
    // "2 Replies. Reply" or "Reply"
    const match = ariaLabel?.match(/(\d[\d,]*)\s*(?:Repl|reply)/i);
    metrics.replies = match ? parseInt(match[1].replace(/,/g, '')) : 0;
  }
  
  // VIEWS: Look for analytics link or view count text
  const viewsElement = await tweetArticle.$('a[href*="/analytics"]');
  if (viewsElement) {
    const viewsText = await viewsElement.textContent();
    // "2.2K Views" or "1,234 Views"
    metrics.views = this.parseViewCount(viewsText);
  }
  
  log({ 
    op: 'public_tweet_extraction', 
    tweet_id: tweetId,
    likes: metrics.likes,
    retweets: metrics.retweets,
    replies: metrics.replies,
    views: metrics.views
  });
  
  return metrics;
}
```

**Benefits:**
- ‚úÖ Most stable extraction method (aria-label rarely changes)
- ‚úÖ Works without analytics access
- ‚úÖ Gets real engagement data
- ‚úÖ Can extract views from multiple sources

---

## üîß Improvement 4: Health Monitoring & Auto-Recovery

### **Add scraper health metrics:**

```typescript
class ScraperHealthMonitor {
  private stats = {
    total_attempts: 0,
    successful_extractions: 0,
    failed_extractions: 0,
    fallback_uses: 0,
    validation_failures: 0,
    strategies_used: {} as Record<string, number>,
    last_24h_success_rate: 0
  };
  
  recordExtraction(result: ExtractionResult) {
    this.stats.total_attempts++;
    
    if (result.success) {
      this.stats.successful_extractions++;
      this.stats.strategies_used[result.strategy] = 
        (this.stats.strategies_used[result.strategy] || 0) + 1;
    } else {
      this.stats.failed_extractions++;
    }
    
    if (result.usedFallback) {
      this.stats.fallback_uses++;
    }
    
    if (result.validationIssues && result.validationIssues.length > 0) {
      this.stats.validation_failures++;
    }
    
    // Calculate rolling success rate
    this.updateSuccessRate();
    
    // Auto-alert if degraded
    if (this.stats.last_24h_success_rate < 0.7) {
      this.alertDegradedPerformance();
    }
  }
  
  async alertDegradedPerformance() {
    log({ 
      op: 'scraper_degraded', 
      success_rate: this.stats.last_24h_success_rate,
      total_failures: this.stats.failed_extractions,
      recommendation: 'Check Twitter DOM changes or rate limits'
    });
    
    // Store in database for dashboard alert
    await supabase.from('system_alerts').insert({
      alert_type: 'scraper_degraded',
      severity: 'high',
      message: `Scraper success rate: ${(this.stats.last_24h_success_rate * 100).toFixed(1)}%`,
      metadata: this.stats
    });
  }
  
  getHealthReport() {
    return {
      status: this.stats.last_24h_success_rate > 0.9 ? 'healthy' : 
              this.stats.last_24h_success_rate > 0.7 ? 'degraded' : 'critical',
      success_rate: this.stats.last_24h_success_rate,
      total_attempts: this.stats.total_attempts,
      preferred_strategy: Object.entries(this.stats.strategies_used)
        .sort((a, b) => b[1] - a[1])[0]?.[0],
      ...this.stats
    };
  }
}
```

**Benefits:**
- ‚úÖ Detects when scraper is degraded
- ‚úÖ Alerts you automatically
- ‚úÖ Shows which strategy is most reliable
- ‚úÖ Tracks success rate over time

---

## üîß Improvement 5: Dashboard Verification Loop

### **Problem:** Data might be stored but not displayed

**Add end-to-end verification:**

```typescript
async verifyDataFlowComplete(tweetId: string): Promise<boolean> {
  // Step 1: Check if scraped to outcomes
  const { data: outcome } = await supabase
    .from('outcomes')
    .select('*')
    .eq('tweet_id', tweetId)
    .order('collected_at', { ascending: false })
    .limit(1)
    .single();
  
  if (!outcome) {
    log({ op: 'verification_failed', tweet_id: tweetId, stage: 'outcomes_missing' });
    return false;
  }
  
  // Step 2: Check if synced to content_metadata
  const { data: content } = await supabase
    .from('content_metadata')
    .select('actual_impressions, actual_likes, actual_retweets')
    .eq('tweet_id', tweetId)
    .single();
  
  if (!content || content.actual_impressions === null) {
    log({ op: 'verification_failed', tweet_id: tweetId, stage: 'content_metadata_not_synced' });
    
    // AUTO-FIX: Sync now
    await this.syncOutcomesToContentMetadata(tweetId);
    return false;
  }
  
  // Step 3: Verify values match
  if (content.actual_impressions !== outcome.impressions) {
    log({ 
      op: 'verification_mismatch', 
      tweet_id: tweetId,
      outcomes_value: outcome.impressions,
      content_metadata_value: content.actual_impressions
    });
  }
  
  log({ op: 'verification_success', tweet_id: tweetId });
  return true;
}
```

**Benefits:**
- ‚úÖ Ensures data reaches dashboard
- ‚úÖ Auto-fixes sync issues
- ‚úÖ Detects discrepancies
- ‚úÖ Logs verification results

---

## üìä Implementation Priority

### **Phase 1: Reliability (This Week)**
1. ‚úÖ **Add public tweet extraction** (most reliable method)
2. ‚úÖ **Add multi-strategy selection** (try multiple, pick best)
3. ‚úÖ **Add validation** (reject clearly wrong data)

**Files to modify:**
- `src/scrapers/bulletproofTwitterScraper.ts`
- `src/jobs/metricsScraperJob.ts`

**Expected improvement:** 60% ‚Üí 95% success rate

---

### **Phase 2: Monitoring (Next Week)**
4. ‚úÖ **Add health monitoring** (track success rate)
5. ‚úÖ **Add dashboard verification** (end-to-end check)
6. ‚úÖ **Add auto-recovery** (fix common issues)

**Files to modify:**
- `src/scrapers/scraperHealthMonitor.ts` (new file)
- `src/jobs/metricsScraperJob.ts`
- `src/dashboard/systemHealthDashboard.ts`

**Expected improvement:** Detect issues within 1 hour, auto-fix 80% of problems

---

### **Phase 3: Intelligence (Future)**
7. ‚úÖ **Learn optimal extraction strategy per tweet type**
8. ‚úÖ **Predict when scraping will fail (rate limits, etc)**
9. ‚úÖ **Auto-adjust batch size based on success rate**

**Expected improvement:** 95% ‚Üí 99% success rate, autonomous operation

---

## üéØ Success Metrics

**Current (Nov 5, 4 PM):**
- Success rate: ~60% (regex only)
- Manual intervention: Required when broken
- Recovery time: Hours (need to deploy fix)

**After Phase 1:**
- Success rate: ~95% (multi-strategy)
- Manual intervention: Rare
- Recovery time: Minutes (auto-fallback)

**After Phase 2:**
- Success rate: ~95%
- Manual intervention: None (auto-recovery)
- Recovery time: Seconds (auto-fix)
- Alert time: < 1 hour (health monitoring)

**After Phase 3:**
- Success rate: ~99%
- Manual intervention: None
- Recovery time: Immediate
- Predictive: Yes (avoid failures before they happen)

---

## üöÄ Quick Wins (Deploy Today)

### **1. Add Public Tweet Extraction (30 min)**
- Most stable method
- Works for all tweet types
- Doesn't rely on analytics page

### **2. Add Basic Validation (15 min)**
- Reject metrics where views=0 but tweet is >24h old
- Flag unrealistic engagement rates
- Log suspicious data

### **3. Add Verification Loop (15 min)**
- Check if data reaches dashboard
- Auto-sync if missing
- Log verification results

**Total time:** ~1 hour  
**Expected impact:** 60% ‚Üí 85% success rate immediately

---

## üìù Next Steps

1. **Deploy Phase 1 improvements** (public tweet extraction + validation)
2. **Monitor for 24 hours** (verify success rate improves)
3. **Deploy Phase 2** (health monitoring + auto-recovery)
4. **Review health dashboard** (identify remaining issues)
5. **Plan Phase 3** (ML-based optimization)

---

**Ready to implement Phase 1? It will take ~1 hour and make scraping significantly more reliable.**

